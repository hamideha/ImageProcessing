{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing project"
      ],
      "metadata": {
        "id": "2_-uD0p7JVLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and load Python dependencies"
      ],
      "metadata": {
        "id": "n-9scnWioqi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "8SKjHCzeotXD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and unzip the DIV2K [dataset](https://data.vision.ee.ethz.ch/cvl/DIV2K/)"
      ],
      "metadata": {
        "id": "Q-nsMMK-scNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip"
      ],
      "metadata": {
        "id": "m8s-Nc1uvH_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"DIV2K_train_HR.zip\"\n",
        "!unzip \"DIV2K_valid_HR.zip\"\n",
        "!mv ./DIV2K_valid_HR/* ./DIV2K_train_HR\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "4LAidMKBJl8X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR get dataset from drive"
      ],
      "metadata": {
        "id": "8ucJzR6GfzeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/School/2022-2023/Winter/ELECENG 4TN4/sr_cnn/DIV2K_train_HR.zip\"\n",
        "!unzip \"/content/drive/MyDrive/School/2022-2023/Winter/ELECENG 4TN4/sr_cnn/DIV2K_valid_HR.zip\"\n",
        "!mv ./DIV2K_valid_HR ./DIV2K_train_HR\n",
        "clear_output()\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "CfikBdr2gExv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model\n"
      ],
      "metadata": {
        "id": "uckkiiXqWrSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(scale):\n",
        "  kernel_size = 3\n",
        "  conv_args = {\n",
        "    \"activation\": \"relu\",\n",
        "    \"padding\": \"same\",\n",
        "  }\n",
        "\n",
        "  input = Input(shape=(None, None, 1))\n",
        "\n",
        "  input = input / 255\n",
        "\n",
        "  x = Conv2D(32, kernel_size, **conv_args)(input)\n",
        "  x = Conv2D(64, kernel_size, **conv_args)(x)\n",
        "  x = Conv2D(128, kernel_size, **conv_args)(x)\n",
        "  x = UpSampling2D(scale)(x)\n",
        "  x = Conv2D(64, kernel_size, **conv_args)(x)\n",
        "  x = Conv2D(32, kernel_size, **conv_args)(x)\n",
        "  x = Conv2D(1, kernel_size, activation=None, padding='same')(x)\n",
        "  x = Activation('tanh')(x)\n",
        "  x = x * 127.5 + 127.5\n",
        "\n",
        "  model = Model([input], x)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "  model.compile(loss='mse', optimizer=optimizer)\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "OqnHLGFfWwyc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Data"
      ],
      "metadata": {
        "id": "QhWEaGlTJgUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder:\n",
        "  def __init__(self, image):\n",
        "    self.image = image\n",
        "    self.ycbcr = self.rgb2ycbcr(cv2.split(image))\n",
        "\n",
        "  def encode(self):\n",
        "    '''\n",
        "    Downsamples image in YCbCr colorspace\n",
        "    Returns: Downsampled Y, Cb, Cr channels as tuple\n",
        "    '''\n",
        "    B, G, R = cv2.split(self.image)\n",
        "\n",
        "    ycbcr = self.rgb2ycbcr((R, G, B))\n",
        "\n",
        "    # Downsample Y by a factor of 2\n",
        "    Y = self.downsample(ycbcr[0], 2)\n",
        "\n",
        "    # Downsample Cb and Cr by a factor of 4\n",
        "    Cb = self.downsample(ycbcr[1], 4)\n",
        "    Cr = self.downsample(ycbcr[2], 4)\n",
        "\n",
        "    self.ycbcr = (Y, Cb, Cr)\n",
        "    \n",
        "  def rgb2ycbcr(self, rgb):\n",
        "    '''\n",
        "    Convert RGB colorspace to YCbCr colorspace\n",
        "    Parameters: R, G, B channels\n",
        "    Returns: Y, Cb, Cr channels as tuple\n",
        "    '''\n",
        "    R, G, B = rgb\n",
        "    Y = 0.257*R + 0.504*G + 0.098*B + 16\n",
        "    Cb = -0.148*R - 0.291*G + 0.439*B + 128\n",
        "    Cr = 0.439*R - 0.368*G - 0.071*B + 128\n",
        "\n",
        "    Y = np.clip(Y, 0, 255).astype(np.uint8)\n",
        "    Cb = np.clip(Cb, 0, 255).astype(np.uint8)\n",
        "    Cr = np.clip(Cr, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return (Y, Cb, Cr)\n",
        "\n",
        "  def downsample(self, channel, factor):\n",
        "    return channel[::factor, ::factor]\n",
        "    \n",
        "  def get_ycbcr(self):\n",
        "    return self.ycbcr"
      ],
      "metadata": {
        "id": "X0NSGsUCN6PZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  x_Y = []\n",
        "  x_Cb = []\n",
        "  x_Cr = []\n",
        "  y_Y = []\n",
        "  y_Cb = []\n",
        "  y_Cr = []\n",
        "\n",
        "  imgs = os.listdir(\"./DIV2K_train_HR\")\n",
        "\n",
        "  for img_path in tqdm(imgs):\n",
        "    img = cv2.imread(f\"./DIV2K_train_HR/{img_path}\", 1)\n",
        "    B, G, R = cv2.split(img)\n",
        "\n",
        "    encoder = Encoder(img)\n",
        "    ycbcr = encoder.rgb2ycbcr((R, G, B))\n",
        "    y_channel, Cb_channel, Cr_channel = ycbcr\n",
        "\n",
        "    Y_out = cv2.resize(y_channel, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "    Cb_out = cv2.resize(Cb_channel, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "    Cr_out = cv2.resize(Cr_channel, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    Y_in = encoder.downsample(Y_out, 2)\n",
        "    Cb_in = encoder.downsample(Cb_out, 4)\n",
        "    Cr_in = encoder.downsample(Cr_out, 4)\n",
        "\n",
        "    x_Y.append(Y_in)\n",
        "    x_Cb.append(Cb_in)\n",
        "    x_Cr.append(Cr_in)\n",
        "    y_Y.append(Y_out)\n",
        "    y_Cb.append(Cb_out)\n",
        "    y_Cr.append(Cr_out)\n",
        "\n",
        "  x_Y = np.array(x_Y)\n",
        "  x_Cb = np.array(x_Cb)\n",
        "  x_Cr = np.array(x_Cr)\n",
        "  y_Y = np.array(y_Y)\n",
        "  y_Cb = np.array(y_Cb)\n",
        "  y_Cr = np.array(y_Cr)\n",
        "\n",
        "  return x_Y, x_Cb, x_Cr, y_Y, y_Cb, y_Cr"
      ],
      "metadata": {
        "id": "v8Wq1wHQHV-M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_model = get_model(2)\n",
        "Cb_model = get_model(4)\n",
        "Cr_model = get_model(4)"
      ],
      "metadata": {
        "id": "59u8_jnhijDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2a79a1-0c4d-4fbe-ef42-dd0f3a8765e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 1)]   0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, None, None, 32)    320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, None, None, 64)    18496     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, None, None, 128)  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, None, None, 64)    73792     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, None, None, 32)    18464     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, None, None, 1)     289       \n",
            "                                                                 \n",
            " activation (Activation)     (None, None, None, 1)     0         \n",
            "                                                                 \n",
            " tf.math.multiply (TFOpLambd  (None, None, None, 1)    0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " tf.__operators__.add (TFOpL  (None, None, None, 1)    0         \n",
            " ambda)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 185,217\n",
            "Trainable params: 185,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None, None, 1)]   0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, None, None, 32)    320       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, None, None, 64)    18496     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, None, None, 128)  0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, None, None, 64)    73792     \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, None, None, 32)    18464     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, None, None, 1)     289       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, None, None, 1)     0         \n",
            "                                                                 \n",
            " tf.math.multiply_1 (TFOpLam  (None, None, None, 1)    0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " tf.__operators__.add_1 (TFO  (None, None, None, 1)    0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 185,217\n",
            "Trainable params: 185,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None, None, 1)]   0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, None, None, 32)    320       \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, None, None, 64)    18496     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, None, None, 128)  0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, None, None, 64)    73792     \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, None, None, 32)    18464     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, None, None, 1)     289       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, None, None, 1)     0         \n",
            "                                                                 \n",
            " tf.math.multiply_2 (TFOpLam  (None, None, None, 1)    0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " tf.__operators__.add_2 (TFO  (None, None, None, 1)    0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 185,217\n",
            "Trainable params: 185,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_Y, x_Cb, x_Cr, y_Y, y_Cb, y_Cr = get_data()"
      ],
      "metadata": {
        "id": "DDanBGbyeeSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5be6831-f9e0-4ce8-cb92-3f4cf21c2e61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900/900 [04:16<00:00,  3.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model"
      ],
      "metadata": {
        "id": "uIN1fVx7AkAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size = 4\n",
        "epochs = 100\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "def tbCallback(model):\n",
        "  return tf.keras.callbacks.TensorBoard(log_dir=f'./Graph/{model}/', histogram_freq=0, write_graph=True, write_images=True)\n",
        "def save_model_callback(model):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(\n",
        "      f'model/{model}.h5',\n",
        "      monitor='val_loss',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      mode='min',\n",
        "      save_freq='epoch'\n",
        "  )\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_Y, y_Y, test_size=0.2, random_state=42)\n",
        "print(\"\\n\\nTraining Y channel model... \\n\")\n",
        "Y_model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[save_model_callback('Y_model'), tbCallback('Y_model'), stop_early])\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_Cb, y_Cb, test_size=0.2, random_state=42)\n",
        "print(\"\\n\\nTraining Cb channel model... \\n\")\n",
        "Cb_model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[save_model_callback('Cb_model'), tbCallback('Cb_model'), stop_early])\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_Cr, y_Cr, test_size=0.2, random_state=42)\n",
        "print(\"\\n\\nTraining Cr channel model... \\n\")\n",
        "Cr_model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[save_model_callback('Cr_model'), tbCallback('Cr_model'), stop_early])"
      ],
      "metadata": {
        "id": "x6KSMfn0AnuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd6f05c-e190-4c2f-f029-867b54b6c411"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Training Y channel model... \n",
            "\n",
            "Epoch 1/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 3857.3743\n",
            "Epoch 1: val_loss improved from inf to 2486.01440, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 4s 10ms/step - loss: 3854.9573 - val_loss: 2486.0144\n",
            "Epoch 2/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 2143.0779\n",
            "Epoch 2: val_loss improved from 2486.01440 to 2269.68652, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 2129.2993 - val_loss: 2269.6865\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 1805.2997\n",
            "Epoch 3: val_loss improved from 2269.68652 to 1615.85046, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1805.2997 - val_loss: 1615.8505\n",
            "Epoch 4/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 1583.9614\n",
            "Epoch 4: val_loss improved from 1615.85046 to 1378.03271, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1573.4833 - val_loss: 1378.0327\n",
            "Epoch 5/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 1329.7316\n",
            "Epoch 5: val_loss improved from 1378.03271 to 1092.91052, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1332.2207 - val_loss: 1092.9105\n",
            "Epoch 6/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 1110.7587\n",
            "Epoch 6: val_loss improved from 1092.91052 to 980.22455, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 1112.3545 - val_loss: 980.2245\n",
            "Epoch 7/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 856.4556\n",
            "Epoch 7: val_loss improved from 980.22455 to 634.44153, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 859.8180 - val_loss: 634.4415\n",
            "Epoch 8/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 553.4993\n",
            "Epoch 8: val_loss improved from 634.44153 to 607.60254, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 551.1399 - val_loss: 607.6025\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 397.6992\n",
            "Epoch 9: val_loss improved from 607.60254 to 327.73108, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 397.6992 - val_loss: 327.7311\n",
            "Epoch 10/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 302.6076\n",
            "Epoch 10: val_loss did not improve from 327.73108\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 301.8042 - val_loss: 336.1337\n",
            "Epoch 11/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 280.3714\n",
            "Epoch 11: val_loss improved from 327.73108 to 260.00446, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 277.8480 - val_loss: 260.0045\n",
            "Epoch 12/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 250.2867\n",
            "Epoch 12: val_loss did not improve from 260.00446\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 250.6239 - val_loss: 288.7228\n",
            "Epoch 13/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 240.7856\n",
            "Epoch 13: val_loss improved from 260.00446 to 230.17517, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 241.5246 - val_loss: 230.1752\n",
            "Epoch 14/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 226.9449\n",
            "Epoch 14: val_loss improved from 230.17517 to 223.46812, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 226.7456 - val_loss: 223.4681\n",
            "Epoch 15/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 209.7930\n",
            "Epoch 15: val_loss improved from 223.46812 to 207.13727, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 209.7624 - val_loss: 207.1373\n",
            "Epoch 16/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 203.3024\n",
            "Epoch 16: val_loss improved from 207.13727 to 203.50020, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 202.2185 - val_loss: 203.5002\n",
            "Epoch 17/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 197.5165\n",
            "Epoch 17: val_loss improved from 203.50020 to 195.30182, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 198.3892 - val_loss: 195.3018\n",
            "Epoch 18/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 190.6623\n",
            "Epoch 18: val_loss did not improve from 195.30182\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 191.9153 - val_loss: 195.6701\n",
            "Epoch 19/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 193.8047\n",
            "Epoch 19: val_loss improved from 195.30182 to 183.69286, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 192.2464 - val_loss: 183.6929\n",
            "Epoch 20/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 174.6612\n",
            "Epoch 20: val_loss improved from 183.69286 to 182.36830, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 175.1221 - val_loss: 182.3683\n",
            "Epoch 21/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 173.0494\n",
            "Epoch 21: val_loss improved from 182.36830 to 175.06131, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 173.9104 - val_loss: 175.0613\n",
            "Epoch 22/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 171.9013\n",
            "Epoch 22: val_loss improved from 175.06131 to 173.39690, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 171.3524 - val_loss: 173.3969\n",
            "Epoch 23/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 169.0014\n",
            "Epoch 23: val_loss did not improve from 173.39690\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 168.6362 - val_loss: 179.8399\n",
            "Epoch 24/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 167.8817\n",
            "Epoch 24: val_loss improved from 173.39690 to 168.69507, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 167.4128 - val_loss: 168.6951\n",
            "Epoch 25/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 162.8880\n",
            "Epoch 25: val_loss did not improve from 168.69507\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 162.7979 - val_loss: 169.3423\n",
            "Epoch 26/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 161.4162\n",
            "Epoch 26: val_loss improved from 168.69507 to 167.22726, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 162.0858 - val_loss: 167.2273\n",
            "Epoch 27/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 162.3761\n",
            "Epoch 27: val_loss did not improve from 167.22726\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 162.2453 - val_loss: 185.0560\n",
            "Epoch 28/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 154.9337\n",
            "Epoch 28: val_loss improved from 167.22726 to 157.16698, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 154.4393 - val_loss: 157.1670\n",
            "Epoch 29/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 153.5717\n",
            "Epoch 29: val_loss did not improve from 157.16698\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 154.3105 - val_loss: 166.4854\n",
            "Epoch 30/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 152.7598\n",
            "Epoch 30: val_loss improved from 157.16698 to 154.49823, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 152.4232 - val_loss: 154.4982\n",
            "Epoch 31/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 151.4494\n",
            "Epoch 31: val_loss improved from 154.49823 to 153.44122, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 150.7484 - val_loss: 153.4412\n",
            "Epoch 32/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 151.0713\n",
            "Epoch 32: val_loss improved from 153.44122 to 152.64636, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 150.4460 - val_loss: 152.6464\n",
            "Epoch 33/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 148.7384\n",
            "Epoch 33: val_loss did not improve from 152.64636\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 148.1568 - val_loss: 157.5684\n",
            "Epoch 34/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 151.6577\n",
            "Epoch 34: val_loss improved from 152.64636 to 151.13275, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 151.5862 - val_loss: 151.1328\n",
            "Epoch 35/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 147.5361\n",
            "Epoch 35: val_loss did not improve from 151.13275\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 147.2021 - val_loss: 156.8127\n",
            "Epoch 36/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 145.6540\n",
            "Epoch 36: val_loss improved from 151.13275 to 150.11897, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 144.8302 - val_loss: 150.1190\n",
            "Epoch 37/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 146.4973\n",
            "Epoch 37: val_loss did not improve from 150.11897\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 145.9243 - val_loss: 159.1560\n",
            "Epoch 38/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 148.1018\n",
            "Epoch 38: val_loss did not improve from 150.11897\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 147.7949 - val_loss: 152.8285\n",
            "Epoch 39/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 144.6107\n",
            "Epoch 39: val_loss improved from 150.11897 to 147.55376, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 144.0706 - val_loss: 147.5538\n",
            "Epoch 40/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 142.1509\n",
            "Epoch 40: val_loss did not improve from 147.55376\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 142.3061 - val_loss: 148.4576\n",
            "Epoch 41/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 141.9121\n",
            "Epoch 41: val_loss did not improve from 147.55376\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 142.2061 - val_loss: 182.3220\n",
            "Epoch 42/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 143.6089\n",
            "Epoch 42: val_loss improved from 147.55376 to 147.34035, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 143.5976 - val_loss: 147.3403\n",
            "Epoch 43/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 140.0441\n",
            "Epoch 43: val_loss improved from 147.34035 to 145.85800, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 139.8812 - val_loss: 145.8580\n",
            "Epoch 44/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 141.1856\n",
            "Epoch 44: val_loss improved from 145.85800 to 143.19008, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 141.1483 - val_loss: 143.1901\n",
            "Epoch 45/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 142.8849\n",
            "Epoch 45: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 143.2120 - val_loss: 143.4687\n",
            "Epoch 46/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 142.1418\n",
            "Epoch 46: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 142.4032 - val_loss: 148.2697\n",
            "Epoch 47/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 139.1307\n",
            "Epoch 47: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 140.7966 - val_loss: 148.6287\n",
            "Epoch 48/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 137.3341\n",
            "Epoch 48: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 136.8710 - val_loss: 143.2247\n",
            "Epoch 49/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 136.4258\n",
            "Epoch 49: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 137.2350 - val_loss: 150.8823\n",
            "Epoch 50/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 142.1189\n",
            "Epoch 50: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 142.3050 - val_loss: 143.9376\n",
            "Epoch 51/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 139.3166\n",
            "Epoch 51: val_loss did not improve from 143.19008\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 139.3563 - val_loss: 161.0261\n",
            "Epoch 52/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 136.2588\n",
            "Epoch 52: val_loss improved from 143.19008 to 140.80968, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 136.2789 - val_loss: 140.8097\n",
            "Epoch 53/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 136.6321\n",
            "Epoch 53: val_loss improved from 140.80968 to 139.79851, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 135.4710 - val_loss: 139.7985\n",
            "Epoch 54/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 137.5616\n",
            "Epoch 54: val_loss did not improve from 139.79851\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 137.5313 - val_loss: 141.9343\n",
            "Epoch 55/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 137.9509\n",
            "Epoch 55: val_loss did not improve from 139.79851\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 137.4966 - val_loss: 145.8080\n",
            "Epoch 56/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 138.1802\n",
            "Epoch 56: val_loss did not improve from 139.79851\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 137.2062 - val_loss: 141.9406\n",
            "Epoch 57/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 135.5403\n",
            "Epoch 57: val_loss did not improve from 139.79851\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 135.1060 - val_loss: 142.8264\n",
            "Epoch 58/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 137.0512\n",
            "Epoch 58: val_loss improved from 139.79851 to 139.76230, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 137.3971 - val_loss: 139.7623\n",
            "Epoch 59/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 134.4464\n",
            "Epoch 59: val_loss improved from 139.76230 to 139.28769, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 134.6159 - val_loss: 139.2877\n",
            "Epoch 60/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 133.6912\n",
            "Epoch 60: val_loss did not improve from 139.28769\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 133.8430 - val_loss: 152.2036\n",
            "Epoch 61/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 137.1728\n",
            "Epoch 61: val_loss improved from 139.28769 to 138.20848, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 136.3810 - val_loss: 138.2085\n",
            "Epoch 62/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 135.9324\n",
            "Epoch 62: val_loss did not improve from 138.20848\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 135.5792 - val_loss: 139.9161\n",
            "Epoch 63/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 133.3250\n",
            "Epoch 63: val_loss did not improve from 138.20848\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 133.5729 - val_loss: 138.9383\n",
            "Epoch 64/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 131.8042\n",
            "Epoch 64: val_loss improved from 138.20848 to 136.93959, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 131.2684 - val_loss: 136.9396\n",
            "Epoch 65/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 137.2106\n",
            "Epoch 65: val_loss did not improve from 136.93959\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 136.6130 - val_loss: 142.7434\n",
            "Epoch 66/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 132.0726\n",
            "Epoch 66: val_loss did not improve from 136.93959\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 132.5667 - val_loss: 137.6937\n",
            "Epoch 67/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 132.5856\n",
            "Epoch 67: val_loss improved from 136.93959 to 135.60353, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 131.8491 - val_loss: 135.6035\n",
            "Epoch 68/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.0467\n",
            "Epoch 68: val_loss did not improve from 135.60353\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 130.6329 - val_loss: 138.7446\n",
            "Epoch 69/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 137.3760\n",
            "Epoch 69: val_loss did not improve from 135.60353\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 136.8793 - val_loss: 142.7218\n",
            "Epoch 70/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.9512\n",
            "Epoch 70: val_loss improved from 135.60353 to 135.28537, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 130.7133 - val_loss: 135.2854\n",
            "Epoch 71/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.5182\n",
            "Epoch 71: val_loss did not improve from 135.28537\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 130.7836 - val_loss: 135.4651\n",
            "Epoch 72/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.0889\n",
            "Epoch 72: val_loss did not improve from 135.28537\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 130.3137 - val_loss: 136.0829\n",
            "Epoch 73/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.4718\n",
            "Epoch 73: val_loss improved from 135.28537 to 135.09604, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 129.8447 - val_loss: 135.0960\n",
            "Epoch 74/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 129.1550\n",
            "Epoch 74: val_loss did not improve from 135.09604\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 129.7070 - val_loss: 145.9600\n",
            "Epoch 75/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 127.7968\n",
            "Epoch 75: val_loss did not improve from 135.09604\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 128.6997 - val_loss: 138.0076\n",
            "Epoch 76/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 129.2136\n",
            "Epoch 76: val_loss improved from 135.09604 to 134.57074, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 129.4363 - val_loss: 134.5707\n",
            "Epoch 77/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 132.4536\n",
            "Epoch 77: val_loss did not improve from 134.57074\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 131.4418 - val_loss: 136.7182\n",
            "Epoch 78/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 130.4469\n",
            "Epoch 78: val_loss improved from 134.57074 to 132.95844, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 130.4519 - val_loss: 132.9584\n",
            "Epoch 79/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 129.1790\n",
            "Epoch 79: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 129.6166 - val_loss: 142.1182\n",
            "Epoch 80/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 129.3891\n",
            "Epoch 80: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 128.6843 - val_loss: 134.0359\n",
            "Epoch 81/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 127.7544\n",
            "Epoch 81: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 128.3873 - val_loss: 140.4950\n",
            "Epoch 82/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 129.3967\n",
            "Epoch 82: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 128.5922 - val_loss: 133.0618\n",
            "Epoch 83/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 127.0326\n",
            "Epoch 83: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.6800 - val_loss: 133.0931\n",
            "Epoch 84/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 126.7352\n",
            "Epoch 84: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.8218 - val_loss: 133.7968\n",
            "Epoch 85/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 128.3213\n",
            "Epoch 85: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 128.1266 - val_loss: 135.0775\n",
            "Epoch 86/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 126.6172\n",
            "Epoch 86: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.6095 - val_loss: 136.9545\n",
            "Epoch 87/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 124.7600\n",
            "Epoch 87: val_loss did not improve from 132.95844\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.3281 - val_loss: 133.8985\n",
            "Epoch 88/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 125.8008\n",
            "Epoch 88: val_loss improved from 132.95844 to 132.31622, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 125.7555 - val_loss: 132.3162\n",
            "Epoch 89/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 127.8311\n",
            "Epoch 89: val_loss did not improve from 132.31622\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.8480 - val_loss: 134.0209\n",
            "Epoch 90/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 126.3774\n",
            "Epoch 90: val_loss improved from 132.31622 to 131.19461, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.1042 - val_loss: 131.1946\n",
            "Epoch 91/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 125.6046\n",
            "Epoch 91: val_loss did not improve from 131.19461\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 125.2540 - val_loss: 131.8326\n",
            "Epoch 92/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 125.0671\n",
            "Epoch 92: val_loss did not improve from 131.19461\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 124.8335 - val_loss: 131.2729\n",
            "Epoch 93/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 127.7899\n",
            "Epoch 93: val_loss did not improve from 131.19461\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 127.4362 - val_loss: 132.3844\n",
            "Epoch 94/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 125.6873\n",
            "Epoch 94: val_loss did not improve from 131.19461\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 124.7927 - val_loss: 131.2127\n",
            "Epoch 95/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 126.0508\n",
            "Epoch 95: val_loss did not improve from 131.19461\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.0176 - val_loss: 131.2764\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - ETA: 0s - loss: 126.9732\n",
            "Epoch 96: val_loss improved from 131.19461 to 130.60399, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.9732 - val_loss: 130.6040\n",
            "Epoch 97/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 126.6255\n",
            "Epoch 97: val_loss improved from 130.60399 to 130.60068, saving model to model/Y_model.h5\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.2764 - val_loss: 130.6007\n",
            "Epoch 98/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 123.6807\n",
            "Epoch 98: val_loss did not improve from 130.60068\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 123.5713 - val_loss: 131.1783\n",
            "Epoch 99/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 124.0328\n",
            "Epoch 99: val_loss did not improve from 130.60068\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 124.8694 - val_loss: 131.0451\n",
            "Epoch 100/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 126.4133\n",
            "Epoch 100: val_loss did not improve from 130.60068\n",
            "180/180 [==============================] - 2s 9ms/step - loss: 126.0195 - val_loss: 130.7545\n",
            "\n",
            "\n",
            "Training Cb channel model... \n",
            "\n",
            "Epoch 1/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 3847.0481\n",
            "Epoch 1: val_loss improved from inf to 441.21823, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 4s 9ms/step - loss: 3835.2124 - val_loss: 441.2182\n",
            "Epoch 2/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 496.1202\n",
            "Epoch 2: val_loss did not improve from 441.21823\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 493.7378 - val_loss: 748.6799\n",
            "Epoch 3/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 438.7817\n",
            "Epoch 3: val_loss improved from 441.21823 to 314.74438, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 434.3890 - val_loss: 314.7444\n",
            "Epoch 4/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 354.7007\n",
            "Epoch 4: val_loss improved from 314.74438 to 285.18073, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 352.9782 - val_loss: 285.1807\n",
            "Epoch 5/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 368.7477\n",
            "Epoch 5: val_loss improved from 285.18073 to 267.34976, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 366.0378 - val_loss: 267.3498\n",
            "Epoch 6/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 372.7330\n",
            "Epoch 6: val_loss did not improve from 267.34976\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 376.4011 - val_loss: 492.7234\n",
            "Epoch 7/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 281.2319\n",
            "Epoch 7: val_loss improved from 267.34976 to 252.18427, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 285.7539 - val_loss: 252.1843\n",
            "Epoch 8/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 324.3879\n",
            "Epoch 8: val_loss did not improve from 252.18427\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 324.7342 - val_loss: 293.5166\n",
            "Epoch 9/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 273.9484\n",
            "Epoch 9: val_loss did not improve from 252.18427\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 271.4814 - val_loss: 256.1935\n",
            "Epoch 10/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 252.0711\n",
            "Epoch 10: val_loss did not improve from 252.18427\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 254.8228 - val_loss: 272.3468\n",
            "Epoch 11/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 235.6576\n",
            "Epoch 11: val_loss did not improve from 252.18427\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 236.3573 - val_loss: 351.0181\n",
            "Epoch 12/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 243.6551\n",
            "Epoch 12: val_loss improved from 252.18427 to 243.27159, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 242.2247 - val_loss: 243.2716\n",
            "Epoch 13/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 222.0851\n",
            "Epoch 13: val_loss did not improve from 243.27159\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 223.0148 - val_loss: 303.1146\n",
            "Epoch 14/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 215.9264\n",
            "Epoch 14: val_loss improved from 243.27159 to 208.83969, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 214.7878 - val_loss: 208.8397\n",
            "Epoch 15/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 207.1175\n",
            "Epoch 15: val_loss did not improve from 208.83969\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 208.7757 - val_loss: 237.9197\n",
            "Epoch 16/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 200.1467\n",
            "Epoch 16: val_loss improved from 208.83969 to 208.45502, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 200.8175 - val_loss: 208.4550\n",
            "Epoch 17/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 193.6113\n",
            "Epoch 17: val_loss improved from 208.45502 to 185.09293, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 194.0316 - val_loss: 185.0929\n",
            "Epoch 18/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 190.1761\n",
            "Epoch 18: val_loss improved from 185.09293 to 179.97687, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 188.3827 - val_loss: 179.9769\n",
            "Epoch 19/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 188.6375\n",
            "Epoch 19: val_loss did not improve from 179.97687\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 190.6046 - val_loss: 224.3346\n",
            "Epoch 20/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 177.7441\n",
            "Epoch 20: val_loss improved from 179.97687 to 172.05194, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 178.3005 - val_loss: 172.0519\n",
            "Epoch 21/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 172.4414\n",
            "Epoch 21: val_loss did not improve from 172.05194\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 172.3734 - val_loss: 178.4843\n",
            "Epoch 22/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 177.4111\n",
            "Epoch 22: val_loss improved from 172.05194 to 168.85402, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 176.6664 - val_loss: 168.8540\n",
            "Epoch 23/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 160.3393\n",
            "Epoch 23: val_loss did not improve from 168.85402\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 162.1265 - val_loss: 189.8822\n",
            "Epoch 24/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 156.8334\n",
            "Epoch 24: val_loss improved from 168.85402 to 154.78473, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 157.5891 - val_loss: 154.7847\n",
            "Epoch 25/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 155.7581\n",
            "Epoch 25: val_loss improved from 154.78473 to 151.19823, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 155.5346 - val_loss: 151.1982\n",
            "Epoch 26/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 162.3249\n",
            "Epoch 26: val_loss did not improve from 151.19823\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 161.9009 - val_loss: 159.0581\n",
            "Epoch 27/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 142.2352\n",
            "Epoch 27: val_loss improved from 151.19823 to 143.44109, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 143.7749 - val_loss: 143.4411\n",
            "Epoch 28/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 137.6463\n",
            "Epoch 28: val_loss improved from 143.44109 to 141.48164, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 138.0023 - val_loss: 141.4816\n",
            "Epoch 29/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 136.1024\n",
            "Epoch 29: val_loss improved from 141.48164 to 136.28139, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 135.3883 - val_loss: 136.2814\n",
            "Epoch 30/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 117.1383\n",
            "Epoch 30: val_loss improved from 136.28139 to 106.89232, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 116.7181 - val_loss: 106.8923\n",
            "Epoch 31/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 108.4783\n",
            "Epoch 31: val_loss improved from 106.89232 to 98.48267, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 108.0074 - val_loss: 98.4827\n",
            "Epoch 32/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 89.3653\n",
            "Epoch 32: val_loss improved from 98.48267 to 81.99947, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 89.2287 - val_loss: 81.9995\n",
            "Epoch 33/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 76.7367\n",
            "Epoch 33: val_loss improved from 81.99947 to 69.00846, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 77.0430 - val_loss: 69.0085\n",
            "Epoch 34/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 81.3886\n",
            "Epoch 34: val_loss did not improve from 69.00846\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 80.3093 - val_loss: 97.2066\n",
            "Epoch 35/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 59.8321\n",
            "Epoch 35: val_loss improved from 69.00846 to 58.98773, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 59.4077 - val_loss: 58.9877\n",
            "Epoch 36/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 51.6396\n",
            "Epoch 36: val_loss improved from 58.98773 to 47.50311, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 52.4853 - val_loss: 47.5031\n",
            "Epoch 37/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 45.9539\n",
            "Epoch 37: val_loss did not improve from 47.50311\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 46.3080 - val_loss: 50.2616\n",
            "Epoch 38/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 42.3290\n",
            "Epoch 38: val_loss improved from 47.50311 to 39.45613, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 42.2672 - val_loss: 39.4561\n",
            "Epoch 39/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 37.7079\n",
            "Epoch 39: val_loss did not improve from 39.45613\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 37.8154 - val_loss: 41.1065\n",
            "Epoch 40/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 36.2349\n",
            "Epoch 40: val_loss improved from 39.45613 to 34.87272, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 35.7698 - val_loss: 34.8727\n",
            "Epoch 41/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 33.5471\n",
            "Epoch 41: val_loss improved from 34.87272 to 32.69966, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 33.2545 - val_loss: 32.6997\n",
            "Epoch 42/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 32.0349\n",
            "Epoch 42: val_loss improved from 32.69966 to 31.67158, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 32.1667 - val_loss: 31.6716\n",
            "Epoch 43/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 30.6955\n",
            "Epoch 43: val_loss improved from 31.67158 to 31.07976, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 30.8188 - val_loss: 31.0798\n",
            "Epoch 44/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 30.0089\n",
            "Epoch 44: val_loss improved from 31.07976 to 30.18839, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 29.7571 - val_loss: 30.1884\n",
            "Epoch 45/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 29.2405\n",
            "Epoch 45: val_loss did not improve from 30.18839\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 29.3144 - val_loss: 30.7108\n",
            "Epoch 46/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 28.9298\n",
            "Epoch 46: val_loss improved from 30.18839 to 28.97295, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 28.8508 - val_loss: 28.9730\n",
            "Epoch 47/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 28.2151\n",
            "Epoch 47: val_loss improved from 28.97295 to 28.55482, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 28.0658 - val_loss: 28.5548\n",
            "Epoch 48/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 27.6090\n",
            "Epoch 48: val_loss improved from 28.55482 to 27.92099, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 27.4709 - val_loss: 27.9210\n",
            "Epoch 49/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 26.9417\n",
            "Epoch 49: val_loss improved from 27.92099 to 27.16348, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 27.1697 - val_loss: 27.1635\n",
            "Epoch 50/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 27.1607\n",
            "Epoch 50: val_loss improved from 27.16348 to 26.87019, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 26.9246 - val_loss: 26.8702\n",
            "Epoch 51/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 27.5169\n",
            "Epoch 51: val_loss improved from 26.87019 to 26.47757, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 27.1598 - val_loss: 26.4776\n",
            "Epoch 52/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 26.3726\n",
            "Epoch 52: val_loss did not improve from 26.47757\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 26.3315 - val_loss: 28.6958\n",
            "Epoch 53/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 27.4960\n",
            "Epoch 53: val_loss did not improve from 26.47757\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 27.5875 - val_loss: 30.6348\n",
            "Epoch 54/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 26.7362\n",
            "Epoch 54: val_loss improved from 26.47757 to 26.00937, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 26.7958 - val_loss: 26.0094\n",
            "Epoch 55/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 25.8117\n",
            "Epoch 55: val_loss did not improve from 26.00937\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 25.5917 - val_loss: 26.2670\n",
            "Epoch 56/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 25.5564\n",
            "Epoch 56: val_loss improved from 26.00937 to 25.76952, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 25.4336 - val_loss: 25.7695\n",
            "Epoch 57/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 25.9972\n",
            "Epoch 57: val_loss improved from 25.76952 to 25.70988, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 26.0787 - val_loss: 25.7099\n",
            "Epoch 58/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 25.9933\n",
            "Epoch 58: val_loss did not improve from 25.70988\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 26.1735 - val_loss: 28.9778\n",
            "Epoch 59/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 25.7112\n",
            "Epoch 59: val_loss did not improve from 25.70988\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 25.6444 - val_loss: 26.4546\n",
            "Epoch 60/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.6346\n",
            "Epoch 60: val_loss improved from 25.70988 to 25.13588, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 24.5685 - val_loss: 25.1359\n",
            "Epoch 61/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.5462\n",
            "Epoch 61: val_loss did not improve from 25.13588\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.6426 - val_loss: 25.6236\n",
            "Epoch 62/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 24.9419\n",
            "Epoch 62: val_loss improved from 25.13588 to 25.07206, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.8979 - val_loss: 25.0721\n",
            "Epoch 63/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 25.8359\n",
            "Epoch 63: val_loss did not improve from 25.07206\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 25.7835 - val_loss: 25.5847\n",
            "Epoch 64/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 24.5738\n",
            "Epoch 64: val_loss did not improve from 25.07206\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.6810 - val_loss: 26.1297\n",
            "Epoch 65/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.5974\n",
            "Epoch 65: val_loss improved from 25.07206 to 24.88108, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.5597 - val_loss: 24.8811\n",
            "Epoch 66/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.4452\n",
            "Epoch 66: val_loss did not improve from 24.88108\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.3092 - val_loss: 25.4359\n",
            "Epoch 67/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 24.4137\n",
            "Epoch 67: val_loss improved from 24.88108 to 24.75565, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 24.5858 - val_loss: 24.7557\n",
            "Epoch 68/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 24.2140\n",
            "Epoch 68: val_loss improved from 24.75565 to 24.43476, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.0665 - val_loss: 24.4348\n",
            "Epoch 69/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 24.7319\n",
            "Epoch 69: val_loss did not improve from 24.43476\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.8070 - val_loss: 25.4345\n",
            "Epoch 70/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 24.2548\n",
            "Epoch 70: val_loss did not improve from 24.43476\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.1628 - val_loss: 24.6813\n",
            "Epoch 71/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.9870\n",
            "Epoch 71: val_loss improved from 24.43476 to 24.35816, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.1475 - val_loss: 24.3582\n",
            "Epoch 72/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.6894\n",
            "Epoch 72: val_loss did not improve from 24.35816\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.6372 - val_loss: 24.9447\n",
            "Epoch 73/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.7889\n",
            "Epoch 73: val_loss did not improve from 24.35816\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.8295 - val_loss: 25.5490\n",
            "Epoch 74/100\n",
            "175/180 [============================>.] - ETA: 0s - loss: 23.7754\n",
            "Epoch 74: val_loss improved from 24.35816 to 24.31226, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 23.6593 - val_loss: 24.3123\n",
            "Epoch 75/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 24.4130\n",
            "Epoch 75: val_loss improved from 24.31226 to 24.26806, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 24.1850 - val_loss: 24.2681\n",
            "Epoch 76/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.9093\n",
            "Epoch 76: val_loss did not improve from 24.26806\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 24.2101 - val_loss: 25.2267\n",
            "Epoch 77/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.8825\n",
            "Epoch 77: val_loss did not improve from 24.26806\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.9578 - val_loss: 25.7912\n",
            "Epoch 78/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 23.7128\n",
            "Epoch 78: val_loss improved from 24.26806 to 24.22126, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.7208 - val_loss: 24.2213\n",
            "Epoch 79/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 22.8297\n",
            "Epoch 79: val_loss did not improve from 24.22126\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.5736 - val_loss: 25.1141\n",
            "Epoch 80/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.8719\n",
            "Epoch 80: val_loss improved from 24.22126 to 24.09775, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.7504 - val_loss: 24.0977\n",
            "Epoch 81/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.6763\n",
            "Epoch 81: val_loss did not improve from 24.09775\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.6449 - val_loss: 24.1745\n",
            "Epoch 82/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 23.5500\n",
            "Epoch 82: val_loss improved from 24.09775 to 23.96243, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.6130 - val_loss: 23.9624\n",
            "Epoch 83/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.3872\n",
            "Epoch 83: val_loss did not improve from 23.96243\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.3307 - val_loss: 24.0995\n",
            "Epoch 84/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.8977\n",
            "Epoch 84: val_loss did not improve from 23.96243\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.8574 - val_loss: 24.0650\n",
            "Epoch 85/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.7026\n",
            "Epoch 85: val_loss did not improve from 23.96243\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.5974 - val_loss: 24.5348\n",
            "Epoch 86/100\n",
            "174/180 [============================>.] - ETA: 0s - loss: 23.2703\n",
            "Epoch 86: val_loss improved from 23.96243 to 23.87487, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.2793 - val_loss: 23.8749\n",
            "Epoch 87/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 25.3544\n",
            "Epoch 87: val_loss did not improve from 23.87487\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 25.2394 - val_loss: 24.7459\n",
            "Epoch 88/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 23.4697\n",
            "Epoch 88: val_loss did not improve from 23.87487\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.3969 - val_loss: 24.0266\n",
            "Epoch 89/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 22.7693\n",
            "Epoch 89: val_loss did not improve from 23.87487\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 22.8828 - val_loss: 24.0943\n",
            "Epoch 90/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.0524\n",
            "Epoch 90: val_loss improved from 23.87487 to 23.77618, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 2s 8ms/step - loss: 23.0630 - val_loss: 23.7762\n",
            "Epoch 91/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.0216\n",
            "Epoch 91: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.0532 - val_loss: 24.3127\n",
            "Epoch 92/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 22.7718\n",
            "Epoch 92: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.2079 - val_loss: 23.9153\n",
            "Epoch 93/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.0519\n",
            "Epoch 93: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.1437 - val_loss: 26.1204\n",
            "Epoch 94/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 23.8022\n",
            "Epoch 94: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.6477 - val_loss: 23.7903\n",
            "Epoch 95/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 23.3552\n",
            "Epoch 95: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.2658 - val_loss: 25.2264\n",
            "Epoch 96/100\n",
            "177/180 [============================>.] - ETA: 0s - loss: 23.1264\n",
            "Epoch 96: val_loss did not improve from 23.77618\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.1580 - val_loss: 24.7836\n",
            "Epoch 97/100\n",
            "178/180 [============================>.] - ETA: 0s - loss: 22.7692\n",
            "Epoch 97: val_loss improved from 23.77618 to 23.68221, saving model to model/Cb_model.h5\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 22.8606 - val_loss: 23.6822\n",
            "Epoch 98/100\n",
            "179/180 [============================>.] - ETA: 0s - loss: 22.8348\n",
            "Epoch 98: val_loss did not improve from 23.68221\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 22.7578 - val_loss: 24.0263\n",
            "Epoch 99/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 23.5034\n",
            "Epoch 99: val_loss did not improve from 23.68221\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 23.5114 - val_loss: 23.7707\n",
            "Epoch 100/100\n",
            "176/180 [============================>.] - ETA: 0s - loss: 22.9146\n",
            "Epoch 100: val_loss did not improve from 23.68221\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 22.7426 - val_loss: 23.9141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45c9325610>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model and predict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8r8ZmHvXe5ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./Graph.zip ./Graph"
      ],
      "metadata": {
        "id": "OKgtVUZpk1Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cbdea1-a320-470f-ef5d-5aa940cd4143"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: Graph/ (stored 0%)\n",
            "  adding: Graph/Y_model/ (stored 0%)\n",
            "  adding: Graph/Y_model/validation/ (stored 0%)\n",
            "  adding: Graph/Y_model/validation/events.out.tfevents.1680318107.2af94da423fb.826.3.v2 (deflated 77%)\n",
            "  adding: Graph/Y_model/train/ (stored 0%)\n",
            "  adding: Graph/Y_model/train/events.out.tfevents.1680318103.2af94da423fb.826.2.v2 (deflated 89%)\n",
            "  adding: Graph/Cr_model/ (stored 0%)\n",
            "  adding: Graph/Cr_model/validation/ (stored 0%)\n",
            "  adding: Graph/Cr_model/validation/events.out.tfevents.1680317894.2af94da423fb.826.1.v2 (deflated 77%)\n",
            "  adding: Graph/Cr_model/train/ (stored 0%)\n",
            "  adding: Graph/Cr_model/train/events.out.tfevents.1680317881.2af94da423fb.826.0.v2 (deflated 89%)\n",
            "  adding: Graph/Cb_model/ (stored 0%)\n",
            "  adding: Graph/Cb_model/validation/ (stored 0%)\n",
            "  adding: Graph/Cb_model/validation/events.out.tfevents.1680318273.2af94da423fb.826.5.v2 (deflated 77%)\n",
            "  adding: Graph/Cb_model/train/ (stored 0%)\n",
            "  adding: Graph/Cb_model/train/events.out.tfevents.1680318270.2af94da423fb.826.4.v2 (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('./model/Y_model.h5')\n",
        "files.download('./model/Cb_model.h5')\n",
        "files.download('./model/Cr_model.h5')\n",
        "files.download('./Graph.zip')"
      ],
      "metadata": {
        "id": "PhdTXmMVe9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder:\n",
        "    def __init__(self, ycbcr, original_size):\n",
        "        self.ycbcr = ycbcr\n",
        "        self.original_size = original_size\n",
        "\n",
        "    def decode(self):\n",
        "        \"\"\"\n",
        "        Upsamples image in YCbCr colorspace\n",
        "        Parameters: Size of image to upsample to\n",
        "        Returns: Reconstructed image\n",
        "        \"\"\"\n",
        "        Y, Cb, Cr = self.infer()\n",
        "\n",
        "        R, G, B = self.ycbcr2rgb((Y, Cb, Cr))\n",
        "\n",
        "        self.image = cv2.merge((B, G, R))\n",
        "        return cv2.merge((B, G, R))\n",
        "\n",
        "    def ycbcr2rgb(self, ycbcr):\n",
        "        \"\"\"\n",
        "        Convert YCbCr colorspace to RGB colorspace\n",
        "        Parameters: Y, Cb, Cr channels\n",
        "        Returns: R, G, B channels as tuple\n",
        "        \"\"\"\n",
        "        Y, Cb, Cr = ycbcr\n",
        "        Y = self.crop(Y)\n",
        "        Cb = self.crop(Cb)\n",
        "        Cr = self.crop(Cr)\n",
        "\n",
        "        R = 1.164 * (Y - 16) + 1.596 * (Cr - 128)\n",
        "        G = 1.164 * (Y - 16) - 0.392 * (Cb - 128) - 0.813 * (Cr - 128)\n",
        "        B = 1.164 * (Y - 16) + 2.017 * (Cb - 128)\n",
        "\n",
        "        R = np.clip(R, 0, 255).astype(np.uint8)\n",
        "        G = np.clip(G, 0, 255).astype(np.uint8)\n",
        "        B = np.clip(B, 0, 255).astype(np.uint8)\n",
        "\n",
        "        return (R, G, B)\n",
        "\n",
        "    def infer(self):\n",
        "        Y_model = load_model(\"model/Y_model.h5\")\n",
        "        Cb_model = load_model(\"model/Cb_model.h5\")\n",
        "        Cr_model = load_model(\"model/Cr_model.h5\")\n",
        "\n",
        "        Y, Cb, Cr = self.ycbcr\n",
        "\n",
        "        y_Y = np.expand_dims(Y, axis=0)\n",
        "        y_Cb = np.expand_dims(Cb, axis=0)\n",
        "        y_Cr = np.expand_dims(Cr, axis=0)\n",
        "\n",
        "        Y = Y_model.predict(y_Y)\n",
        "        Cb = Cb_model.predict(y_Cb)\n",
        "        Cr = Cr_model.predict(y_Cr)\n",
        "\n",
        "        Y = Y[0,:,:,0]\n",
        "        Cb = Cb[0,:,:,0]\n",
        "        Cr = Cr[0,:,:,0]\n",
        "\n",
        "        return (Y, Cb, Cr)\n",
        "\n",
        "    def crop(self, channel):\n",
        "      height, width = self.original_size[:2]\n",
        "      return channel[0:height, 0:width]\n",
        "\n",
        "    def get_psnr(self, reconstructed_image, original_image):\n",
        "        mse = np.mean((original_image - reconstructed_image) ** 2)\n",
        "        return 10 * math.log10(255.0**2 / mse)\n",
        "\n",
        "    def get_ssim(self, reconstructed_image, original_image):\n",
        "        C1 = (0.01 * 255)**2\n",
        "        C2 = (0.03 * 255)**2\n",
        "\n",
        "        X = reconstructed_image.astype(np.float32)\n",
        "        Y = original_image.astype(np.float32)\n",
        "        window = self.__gaussian_window(11, 1.5)\n",
        "\n",
        "        muX = cv2.filter2D(X, -1, window)[5:-5, 5:-5]\n",
        "        muY = cv2.filter2D(Y, -1, window)[5:-5, 5:-5]\n",
        "\n",
        "        sigmaX_sq = cv2.filter2D(X**2, -1, window)[5:-5, 5:-5] - muX**2\n",
        "        sigmaY_sq = cv2.filter2D(Y**2, -1, window)[5:-5, 5:-5] - muY**2\n",
        "        sigmaXY = cv2.filter2D(X * Y, -1, window)[5:-5, 5:-5] - (muX * muY)\n",
        "\n",
        "        num = (2 * muX * muY + C1) * (2 * sigmaXY + C2)\n",
        "        den = (muX**2 + muY**2 + C1) * (sigmaX_sq + sigmaY_sq + C2)\n",
        "\n",
        "        ssim = num / den\n",
        "\n",
        "        return ssim.mean()\n",
        "\n",
        "    def get_image(self):\n",
        "        return self.image\n",
        "    \n",
        "    def __gaussian_window(self, size = 11, sigma = 1.5):\n",
        "        x = np.linspace(-(size//2), size//2, size)\n",
        "        f = np.exp(-0.5 * x**2 / sigma**2)\n",
        "        kernel = np.outer(f, f)\n",
        "        return kernel / np.sum(kernel)"
      ],
      "metadata": {
        "id": "vIf99_Sp_M_C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    PATH = \"motorcycles.png\"\n",
        "    FILENAME = PATH.split(\"/\")[-1].split(\".\")[0]\n",
        "    EXTENSION = PATH.split(\".\")[-1]\n",
        "    original_image = cv2.imread(PATH, 1)\n",
        "\n",
        "    encoder = Encoder(original_image)\n",
        "    encoder.encode()\n",
        "    downsampled_image = encoder.get_ycbcr()\n",
        "\n",
        "    cv2.imwrite(f\"Y.{EXTENSION}\", downsampled_image[0])\n",
        "    cv2.imwrite(f\"Cb.{EXTENSION}\", downsampled_image[1])\n",
        "    cv2.imwrite(f\"Cr.{EXTENSION}\", downsampled_image[2])\n",
        "\n",
        "    decoder = Decoder(downsampled_image, original_image.shape)\n",
        "    decoder.decode()\n",
        "    final_image = decoder.get_image()\n",
        "\n",
        "    psnr = decoder.get_psnr(final_image, original_image)\n",
        "    print(\"PSNR:\", psnr)\n",
        "\n",
        "    ssim = decoder.get_ssim(final_image, original_image)\n",
        "    print(\"SSIM:\", ssim)\n",
        "\n",
        "    cv2.imwrite(f\"{FILENAME}_upsampled.{EXTENSION}\", final_image)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "FE_Duqjv_puv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8c41bc-64bd-4286-f69e-a08c7b715775"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "PSNR: 32.05317259477626\n",
            "SSIM: 0.8649697\n"
          ]
        }
      ]
    }
  ]
}